{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z83mlUMlEraT"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from copy import deepcopy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IXkCytSDTfLk"
      },
      "outputs": [],
      "source": [
        "weights = np.random.uniform(0,5,1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1JtmMqihT4j_"
      },
      "outputs": [],
      "source": [
        "values = np.random.randint(0, 100, 1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mu3z8GI_DG7v"
      },
      "outputs": [],
      "source": [
        "def knapsack_cost(v, max_weight):\n",
        "    total_weight = np.sum(weights[v.chromosome])\n",
        "    total_value = np.sum(values[v.chromosome])\n",
        "\n",
        "    if total_weight <= max_weight:\n",
        "        return -total_value  # Maximize value\n",
        "    else:\n",
        "        # Increase penalty based on weight excess\n",
        "        penalty_factor = 10 * (total_weight - max_weight)\n",
        "        return -total_value - penalty_factor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_UJeqWuKS67a"
      },
      "outputs": [],
      "source": [
        "class treasure_problem:\n",
        "  def __init__(self):\n",
        "     self.number_of_genes = 1000\n",
        "     self.max_weight = 60 #Store max_weight as an attribute\n",
        "     #Assign a lambda function that calls knapsack_cost with both arguments\n",
        "     self.cost_function = lambda v: knapsack_cost(v, self.max_weight)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l2Gio2mbTF8r"
      },
      "outputs": [],
      "source": [
        "class treasure_individual:\n",
        "  # This class defines the individual for the genetic algorithm. We hope to find the individual which solves our problem\n",
        "  chromosome = None\n",
        "\n",
        "  def __init__(self, prob):    #  This is the constructor for the individual and as such needs the problem to mould the individuals to it\n",
        "    #Create a random individual.\n",
        "    self.chromosome =np.random.choice([True,False],prob.number_of_genes,p=[0.01, 0.99])\n",
        "    self.cost = prob.cost_function(self)\n",
        "\n",
        "\n",
        "  def crossover(self, other_parent):\n",
        "        # Choose two random crossover points\n",
        "        chromosome_length = len(self.chromosome)  # Store length to avoid repeated calls\n",
        "        crossover_point1 = np.random.randint(0, chromosome_length - 1)  # Ensure crossover_point1 is not the last index\n",
        "        crossover_point2 = np.random.randint(crossover_point1 + 1, chromosome_length)\n",
        "\n",
        "        # Create the offspring\n",
        "        offspring1 = deepcopy(self)\n",
        "        offspring2 = deepcopy(other_parent)\n",
        "\n",
        "        # Perform the crossover\n",
        "        offspring1.chromosome[crossover_point1:crossover_point2] = other_parent.chromosome[crossover_point1:crossover_point2]\n",
        "        offspring2.chromosome[crossover_point1:crossover_point2] = self.chromosome[crossover_point1:crossover_point2]\n",
        "\n",
        "        return offspring1, offspring2\n",
        "\n",
        "  def mutate(self, mutation_rate, weights):\n",
        "    mutated_chromosome = deepcopy(self.chromosome)\n",
        "    for i in range(len(mutated_chromosome)):\n",
        "        if mutated_chromosome[i] and np.random.rand() < mutation_rate:  # Only mutate True values\n",
        "            # Define neighborhood indices (e.g., one position to the left and right)\n",
        "            neighbors = [i - 1, i + 1]\n",
        "            # Handle boundary conditions\n",
        "            neighbors = [n for n in neighbors if 0 <= n < len(mutated_chromosome)]\n",
        "\n",
        "            # Find lighter neighbors that are False\n",
        "            lighter_neighbors = [n for n in neighbors\n",
        "                                  if not mutated_chromosome[n] and weights[n] < weights[i]]\n",
        "\n",
        "            if lighter_neighbors:  # If lighter neighbors exist\n",
        "                # Randomly select a lighter neighbor for the swap\n",
        "                swap_index = np.random.choice(lighter_neighbors)\n",
        "\n",
        "                # Perform the swap\n",
        "                mutated_chromosome[i] = False\n",
        "                mutated_chromosome[swap_index] = True\n",
        "            else:\n",
        "              mutated_chromosome[i] = False\n",
        "\n",
        "    self.chromosome = mutated_chromosome\n",
        "    return self\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "grbtJNRWU8gi"
      },
      "outputs": [],
      "source": [
        "ind1 = treasure_individual(treasure_problem())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0TyS9pJ358N2",
        "outputId": "4778c085-8745-4d62-9af0-f71079923858"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-426"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "ind1.cost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D-wynLcy7PUL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-N75PrXVDZ_"
      },
      "source": [
        "To get the Weight of the individual, need to sum the weights of the true values of the individual chromosome."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xS_m2rUZVL7q",
        "outputId": "0f53955a-d958-4a52-94f6-b77a7407e131"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The weight of ind1 is: 28.073705215266315\n"
          ]
        }
      ],
      "source": [
        "# Calculate the weight of ind1\n",
        "ind1_weight = np.sum(weights[ind1.chromosome])\n",
        "\n",
        "print(f\"The weight of ind1 is: {ind1_weight}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fcTbTBp9UeF4"
      },
      "source": [
        "To get the Total Value of an individual, You need to sum the values of the array that has True values.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-x15mMNJV-nv",
        "outputId": "f37133de-c0d2-4a1c-e747-c96c98f29d60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The value of ind1 is: 426\n"
          ]
        }
      ],
      "source": [
        "# Calculate the Value of ind1\n",
        "ind1_value = np.sum(values[ind1.chromosome])\n",
        "\n",
        "print(f\"The value of ind1 is: {ind1_value}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4DDsK-ufWKR4"
      },
      "source": [
        "Total Weight and Value of all Items\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gv289_DxWqA7",
        "outputId": "72a123d6-448b-4611-8406-a1166cc1fb9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The total value of all items is: 49124\n",
            "The total weight of all items is: 2445.9439861340397\n"
          ]
        }
      ],
      "source": [
        "# Total value of all items:\n",
        "total_value = np.sum(values)\n",
        "print(f\"The total value of all items is: {total_value}\")\n",
        "\n",
        "#Total Weight of all items:\n",
        "total_weight = np.sum(weights)\n",
        "print(f\"The total weight of all items is: {total_weight}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aSl5IlsIxchp"
      },
      "outputs": [],
      "source": [
        "class parameters:\n",
        "  def __init__(self):\n",
        "    self.population_size = 1000\n",
        "    self.gene_mutation_rate = 0.8\n",
        "    self.gene_mutation_range = 0.75\n",
        "    self.birth_rate_per_generation = 1\n",
        "    self.max_number_of_generations = 100\n",
        "    self.weights = weights\n",
        "    self.values = values\n",
        "    self.max_weight = 60"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bm6kUS4fzESy"
      },
      "outputs": [],
      "source": [
        "def choose_parents(population_size):\n",
        "  index1_parent = np.random.randint(0,population_size)\n",
        "  index2_parent = np.random.randint(0,population_size)\n",
        "  if index1_parent == index2_parent:\n",
        "    return choose_parents(population_size)\n",
        "  return index1_parent, index2_parent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KIitMtYoKDyJ"
      },
      "outputs": [],
      "source": [
        "def run_genetic(prob, params):\n",
        "  # Read Variables\n",
        "  population_size = params.population_size\n",
        "  rate_of_gene_mutation = params.gene_mutation_rate\n",
        "  # range_of_gene_mutation = params.gene_mutation_range\n",
        "  # explore_crossover = params.explore_crossover_range\n",
        "  cost_function = prob.cost_function\n",
        "  number_of_children_per_generation = params.birth_rate_per_generation * population_size\n",
        "  max_number_of_generations = params.max_number_of_generations\n",
        "  # acceptable_cost = prob.acceptable_cost\n",
        "  max_weight = params.max_weight\n",
        "  weights = params.weights\n",
        "  values = params.values\n",
        "\n",
        "  # Create Our Population\n",
        "  population = []\n",
        "  best_solution = treasure_individual(prob)\n",
        "  best_solution.cost = -100000\n",
        "\n",
        "\n",
        "  for i in range(population_size):\n",
        "    new_individual = treasure_individual(prob)\n",
        "    if new_individual.cost > best_solution.cost:\n",
        "      best_solution = deepcopy(new_individual)\n",
        "    population.append(new_individual)\n",
        "\n",
        "\n",
        "\n",
        "  # Start Loop\n",
        "  for i in range(max_number_of_generations):\n",
        "    #Start generation loop\n",
        "    children = []\n",
        "    while (len(children) < number_of_children_per_generation):\n",
        "      #choose Parents\n",
        "      parent1_index, parent2_index = choose_parents(population_size)\n",
        "\n",
        "      parent1 = population[parent1_index]\n",
        "      parent2 = population[parent2_index]\n",
        "\n",
        "      # Create children\n",
        "      child1, child2 = parent1.crossover(parent2)\n",
        "      child1.mutate(rate_of_gene_mutation, weights)\n",
        "      child2.mutate(rate_of_gene_mutation, weights)\n",
        "\n",
        "      child1.cost = cost_function(child1)\n",
        "      child2.cost = cost_function(child2)\n",
        "\n",
        "      # add children to population\n",
        "      children.append(child1)\n",
        "      children.append(child2)\n",
        "\n",
        "    #add children\n",
        "    population += children\n",
        "\n",
        "    # sort population\n",
        "    population = sorted(population,key=lambda x: x.cost)\n",
        "\n",
        "    # cull population\n",
        "    population = population[:population_size]\n",
        "\n",
        "    # check solution\n",
        "    if population[0].cost > best_solution.cost:\n",
        "      best_solution = deepcopy(population[0])\n",
        "\n",
        "    print(best_solution.cost)\n",
        "\n",
        "    # Calculate and print average weight of the population\n",
        "    total_population_weight = sum(np.sum(params.weights[individual.chromosome]) for individual in population)\n",
        "    average_weight = total_population_weight / len(population)\n",
        "    print(f\"Average weight of population: {average_weight}\")\n",
        "\n",
        "    # if best_solution.cost < acceptable_cost:\n",
        "    #   break\n",
        "\n",
        "  return (population, best_solution)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "utk6p8qTxRRZ"
      },
      "outputs": [],
      "source": [
        "problem1 = treasure_problem()\n",
        "params1 = parameters()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1eDrqlMaA92S"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rkAROM-3EK5V"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76GdT__jySov",
        "outputId": "1fe34f23-57bf-4c5a-eb7c-2adabd066154"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-58\n",
            "Average weight of population: 23.990125906218772\n",
            "-58\n",
            "Average weight of population: 23.888680083726314\n",
            "-58\n",
            "Average weight of population: 23.707036852908264\n",
            "-58\n",
            "Average weight of population: 23.62335354029766\n",
            "-58\n",
            "Average weight of population: 23.499079712658357\n",
            "-58\n",
            "Average weight of population: 23.515454946966994\n",
            "-58\n",
            "Average weight of population: 23.504445385746013\n",
            "-58\n",
            "Average weight of population: 23.440115109477308\n",
            "-58\n",
            "Average weight of population: 23.457665949314247\n",
            "-58\n",
            "Average weight of population: 23.309475199103957\n",
            "-58\n",
            "Average weight of population: 23.25197399197685\n",
            "-58\n",
            "Average weight of population: 23.188796130935902\n",
            "-58\n",
            "Average weight of population: 23.117048180166897\n",
            "-58\n",
            "Average weight of population: 23.104843286778593\n",
            "-58\n",
            "Average weight of population: 23.027285199130116\n",
            "-58\n",
            "Average weight of population: 23.046968216732303\n",
            "-58\n",
            "Average weight of population: 23.062064055421438\n",
            "-58\n",
            "Average weight of population: 23.125477799154787\n",
            "-58\n",
            "Average weight of population: 23.10568023268494\n",
            "-58\n",
            "Average weight of population: 23.137837830928493\n",
            "-58\n",
            "Average weight of population: 23.228580846897675\n",
            "-58\n",
            "Average weight of population: 23.17786171993591\n",
            "-58\n",
            "Average weight of population: 23.29971519917353\n",
            "-58\n",
            "Average weight of population: 23.277516438931112\n",
            "-58\n",
            "Average weight of population: 23.26408942821453\n",
            "-58\n",
            "Average weight of population: 23.18215444593431\n",
            "-58\n",
            "Average weight of population: 23.269526172188268\n",
            "-58\n",
            "Average weight of population: 23.32951426005855\n",
            "-58\n",
            "Average weight of population: 23.342068905781495\n",
            "-58\n",
            "Average weight of population: 23.288956650190833\n",
            "-58\n",
            "Average weight of population: 23.26766186914591\n",
            "-58\n",
            "Average weight of population: 23.182717578799352\n",
            "-58\n",
            "Average weight of population: 23.20709327173543\n",
            "-58\n",
            "Average weight of population: 23.213655562481268\n",
            "-58\n",
            "Average weight of population: 23.15313041144422\n",
            "-58\n",
            "Average weight of population: 23.151353308506774\n",
            "-58\n",
            "Average weight of population: 23.157985969325285\n",
            "-58\n",
            "Average weight of population: 23.080517106725342\n",
            "-58\n",
            "Average weight of population: 23.06716127893004\n",
            "-58\n",
            "Average weight of population: 23.03919561653441\n",
            "-58\n",
            "Average weight of population: 23.000577199441725\n",
            "-58\n",
            "Average weight of population: 22.977186971421037\n",
            "-58\n",
            "Average weight of population: 22.930987622553825\n",
            "-58\n",
            "Average weight of population: 22.893254834686896\n",
            "-58\n",
            "Average weight of population: 22.869174536946822\n",
            "-58\n",
            "Average weight of population: 22.85514061903525\n",
            "-58\n",
            "Average weight of population: 22.85640453916698\n",
            "-58\n",
            "Average weight of population: 22.858985091980465\n",
            "-58\n",
            "Average weight of population: 22.844276982298013\n",
            "-58\n",
            "Average weight of population: 22.822639598260206\n",
            "-58\n",
            "Average weight of population: 22.781864140885823\n",
            "-58\n",
            "Average weight of population: 22.786226028524354\n",
            "-58\n",
            "Average weight of population: 22.759050862173517\n",
            "-58\n",
            "Average weight of population: 22.748217715556734\n",
            "-58\n",
            "Average weight of population: 22.755979590539916\n",
            "-58\n",
            "Average weight of population: 22.75729679859124\n",
            "-58\n",
            "Average weight of population: 22.75309624970365\n",
            "-58\n",
            "Average weight of population: 22.68685669985642\n",
            "-58\n",
            "Average weight of population: 22.69214402089793\n",
            "-58\n",
            "Average weight of population: 22.698900075394867\n",
            "-58\n",
            "Average weight of population: 22.653504690621507\n",
            "-58\n",
            "Average weight of population: 22.640091478299233\n",
            "-58\n",
            "Average weight of population: 22.605681725169177\n",
            "-58\n",
            "Average weight of population: 22.60242993221398\n",
            "-58\n",
            "Average weight of population: 22.57260775337413\n",
            "-58\n",
            "Average weight of population: 22.570239731822426\n",
            "-58\n",
            "Average weight of population: 22.536480661083562\n",
            "-58\n",
            "Average weight of population: 22.50837486326586\n",
            "-58\n",
            "Average weight of population: 22.522298967536887\n",
            "-58\n",
            "Average weight of population: 22.511576414912863\n",
            "-58\n",
            "Average weight of population: 22.492579716450802\n",
            "-58\n",
            "Average weight of population: 22.511433771005755\n",
            "-58\n",
            "Average weight of population: 22.53006720157187\n",
            "-58\n",
            "Average weight of population: 22.581238266272663\n",
            "-58\n",
            "Average weight of population: 22.577322060719972\n",
            "-58\n",
            "Average weight of population: 22.556942928832214\n",
            "-58\n",
            "Average weight of population: 22.54635375559706\n",
            "-58\n",
            "Average weight of population: 22.605733031471154\n",
            "-58\n",
            "Average weight of population: 22.62459701579405\n",
            "-58\n",
            "Average weight of population: 22.622911413546138\n",
            "-58\n",
            "Average weight of population: 22.57976615890718\n",
            "-58\n",
            "Average weight of population: 22.557229789804087\n",
            "-58\n",
            "Average weight of population: 22.574541297560735\n",
            "-58\n",
            "Average weight of population: 22.599524869380378\n",
            "-58\n",
            "Average weight of population: 22.57058671952795\n",
            "-58\n",
            "Average weight of population: 22.601801845090964\n",
            "-58\n",
            "Average weight of population: 22.622304486551048\n",
            "-58\n",
            "Average weight of population: 22.644950845670845\n",
            "-58\n",
            "Average weight of population: 22.667810282266544\n",
            "-58\n",
            "Average weight of population: 22.695641341859943\n",
            "-58\n",
            "Average weight of population: 22.68434978997354\n",
            "-58\n",
            "Average weight of population: 22.692536709304086\n",
            "-58\n",
            "Average weight of population: 22.729268298695263\n",
            "-58\n",
            "Average weight of population: 22.769725245935195\n",
            "-58\n",
            "Average weight of population: 22.799945332668514\n",
            "-58\n",
            "Average weight of population: 22.761534326722238\n",
            "-58\n",
            "Average weight of population: 22.779187815605617\n",
            "-58\n",
            "Average weight of population: 22.78887715903093\n",
            "-58\n",
            "Average weight of population: 22.782646453913422\n",
            "-58\n",
            "Average weight of population: 22.797765919891663\n"
          ]
        }
      ],
      "source": [
        "pop, best = run_genetic(problem1,params1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9VruLtnylSu",
        "outputId": "b6a7cd6b-f64c-4ea3-fbf1-2f5721d4b9df"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "        True, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False,  True, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "        True, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "best.chromosome"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDJhPo3CynXx",
        "outputId": "8343d748-5a0a-4403-a481-9973ed36c5c2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-58"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "best.cost"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best.weight"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "LfmAvtiKIOtP",
        "outputId": "3ccdf6a4-ee32-45c9-8993-4bfa69b7da41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'treasure_individual' object has no attribute 'weight'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-a3449c49bb89>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'treasure_individual' object has no attribute 'weight'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpNHu52yQwAM"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}